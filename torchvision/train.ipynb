{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torchLibrary.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "357eaa7a6a2947cfa949fe1705f9691e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1426f0d4ce3b47758c9e74b7494d8ad4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_df5eb2a320b941a583940c4e7c4c1de8",
              "IPY_MODEL_4e1e75c2a9aa4e1b89f3e92cd519ed8e"
            ]
          }
        },
        "1426f0d4ce3b47758c9e74b7494d8ad4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df5eb2a320b941a583940c4e7c4c1de8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fe219194d6d848bdb587a70e2067d041",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 167502836,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 167502836,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5665dcd4c1114bbeb51c6e0ecb4cbff3"
          }
        },
        "4e1e75c2a9aa4e1b89f3e92cd519ed8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6075e81c785e4e3cb3953b967b288230",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 160M/160M [00:11&lt;00:00, 14.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2269c10f5d2b425e97116372097c4de1"
          }
        },
        "fe219194d6d848bdb587a70e2067d041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5665dcd4c1114bbeb51c6e0ecb4cbff3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6075e81c785e4e3cb3953b967b288230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2269c10f5d2b425e97116372097c4de1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjynBzNC6xnW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "51c80f59-364d-487b-a58e-83ddcd8b61cb"
      },
      "source": [
        "%%shell\n",
        "\n",
        "pip install cython\n",
        "# Install pycocotools, the version by default in Colab\n",
        "pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.21)\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-ybeoteeu\n",
            "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-ybeoteeu\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (49.2.0)\n",
            "Requirement already satisfied, skipping upgrade: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (0.29.21)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==2.0) (1.15.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp36-cp36m-linux_x86_64.whl size=266458 sha256=b9671b53c09075b59c7e125b8caad4716628779e9bb645eb6f195b6d99ec4a71\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d6_j8iu_/wheels/90/51/41/646daf401c3bc408ff10de34ec76587a9b3ebfac8d21ca5c3a\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Found existing installation: pycocotools 2.0\n",
            "    Uninstalling pycocotools-2.0:\n",
            "      Successfully uninstalled pycocotools-2.0\n",
            "Successfully installed pycocotools-2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay8WRxm6Zsh7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "792e204a-e475-416e-f5ab-c0dc0989f1e4"
      },
      "source": [
        "# To prevent PyTorch bug, downgrade the installed version of numpy.\n",
        "pip install numpy==1.17.4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.17.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/ab/43e678759326f728de861edbef34b8e2ad1b1490505f20e0d1f0716c3bf4/numpy-1.17.4-cp36-cp36m-manylinux1_x86_64.whl (20.0MB)\n",
            "\u001b[K     |████████████████████████████████| 20.0MB 47.1MB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "Successfully installed numpy-1.17.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVkrym1u34ea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "\n",
        "class OpenDataset(torch.utils.data.Dataset):\n",
        "# Class for creating dataset and importing dataset into the Datalader\n",
        "# Transforms means whether or not the image is preprocessed (left/right transform, etc.)\n",
        "    def __init__(self, root, df_path, transforms=None):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "        self.df = df_path\n",
        "        names = pd.read_csv(df_path)[['filename']]\n",
        "        names = names.drop_duplicates()\n",
        "        self.imgs = list(np.array(names['filename'].tolist()))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load image and check image information\n",
        "        img_path = os.path.join(self.root, self.imgs[idx])\n",
        "        if img_path.split('.')[-1] != 'png' : img_path += '.png'\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        box_list, classes = parse_one_annot(self.df, self.imgs[idx])\n",
        "\n",
        "        # Convert to format suitable for learning(torch.tensor type)\n",
        "        boxes = torch.as_tensor(box_list, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(classes, dtype=torch.int64)\n",
        "        image_id = torch.tensor([idx])\n",
        "        # area means the area corresponding to RoI\n",
        "        area_list = [(i[2] - i[0]) * (i[3] - i[1]) for i in box_list]\n",
        "        areas = torch.as_tensor(area_list, dtype=torch.float32)\n",
        "        # whether the roi is hidden from others\n",
        "        # 0 if hidden, 1 if not\n",
        "        iscrowd = torch.zeros((len(boxes),), dtype=torch.int64)\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"image_id\"] = image_id\n",
        "        target[\"area\"] = areas\n",
        "        target[\"iscrowd\"] = iscrowd\n",
        " \n",
        "        if self.transforms is not None:\n",
        "            img, target = self.transforms(img, target)\n",
        " \n",
        "        return img, target\n",
        " \n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jyy5Q3UH4asI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "def get_instance_segmentation_model(num_classes):\n",
        "    # Load a model pre-trained pre-trained on COCO\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    # Replace the classifier with a new one, that has\n",
        "    # Get number of input features for the classifier\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    # Replace the pre-trained head with a new one\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        " \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgxTL8qAAscb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0bd81a1e-26bd-40cc-a270-b29013f2ec0d"
      },
      "source": [
        "%%shell\n",
        "\n",
        "# Download TorchVision repo to use some files from\n",
        "# references/detection\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "git checkout v0.3.0\n",
        "\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/engine.py ../\n",
        "cp references/detection/coco_utils.py ../"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'vision' already exists and is not an empty directory.\n",
            "HEAD is now at be37608 version check against PyTorch's CUDA version\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ8bnxxZ4si7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "import transforms as T\n",
        "\n",
        "def get_transform(train):\n",
        "   transforms = []\n",
        "   # Converts the image, a PIL image, into a PyTorch Tensor\n",
        "   transforms.append(T.ToTensor())\n",
        "   if train:\n",
        "    # Transform the image left and right with 50% probability when learning\n",
        "      transforms.append(T.RandomHorizontalFlip(0.5))\n",
        "   return T.Compose(transforms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfoAz4a65U2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_one_annot(filepath, filename):\n",
        "    # Load image and check position and classname of RoI\n",
        "    # At this time, convert classname to label(integer type).\n",
        "    # The reason it starts from 1 is that 0 is set as the label of the background.\n",
        "    data = pd.read_csv(filepath)\n",
        "    boxes_array = data[data[\"filename\"] == filename][[\"minX\", \"minY\", \"maxX\", \"maxY\"]].values\n",
        "    for i in range(len(boxes_array)) :\n",
        "        minX = boxes_array[i, 0]\n",
        "        minY = boxes_array[i, 1]\n",
        "        maxX = boxes_array[i, 2]\n",
        "        maxY = boxes_array[i, 3]\n",
        "        if minX >= maxX : print(filename + \" : \" + str(minX)+\", \"+str(maxX))\n",
        "        if minY >= maxY : print(filename + \" : \" + str(minY)+\", \"+str(maxY))\n",
        "    classnames = data[data[\"filename\"] == filename][[\"classname\"]]\n",
        "    classes = []\n",
        "    for i in range(len(classnames)) :\n",
        "        if classnames.iloc[i, 0] =='covid-19' : classes.append(1)\n",
        "        elif classnames.iloc[i, 0] =='nodule' : classes.append(2)\n",
        "        elif classnames.iloc[i, 0] =='cancer' : classes.append(3)\n",
        "    return boxes_array, classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtZ6E87T9aSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "285be352-0018-49b3-fe77-034652d1abcc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Need to edit path\n",
        "train_root = '/content/drive/My Drive/test/train/'\n",
        "val_root = '/content/drive/My Drive/test/val/'\n",
        "test_root = '/content/drive/My Drive/test/test'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOiOb3yF7wGk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2655a41-d38e-4ccc-820a-eacaefff4b4a"
      },
      "source": [
        "dataset_train = OpenDataset(train_root,'/content/drive/My Drive/test/train.csv', transforms = get_transform(train=True))\n",
        "dataset_val = OpenDataset(val_root,'/content/drive/My Drive/test/val.csv', transforms = get_transform(train=False))\n",
        "\n",
        "# Randomly reorder images in a dataset\n",
        "torch.manual_seed(1)\n",
        "indices_train = torch.randperm(len(dataset_train)).tolist()\n",
        "indices_val = torch.randperm(len(dataset_val)).tolist()\n",
        "dataset_train = torch.utils.data.Subset(dataset_train, indices_train)\n",
        "dataset_val = torch.utils.data.Subset(dataset_val, indices_val)\n",
        "\n",
        "# Define Dataloader\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    dataset_train, batch_size=16, shuffle=True, num_workers=4,\n",
        "    collate_fn=utils.collate_fn)\n",
        "\n",
        "data_loader_val = torch.utils.data.DataLoader(\n",
        "    dataset_val, batch_size=16, shuffle=False, num_workers=4,\n",
        "    collate_fn=utils.collate_fn)\n",
        "\n",
        "print(\"We have: {} examples, {} are training and {} testing\".format(len(dataset_train)+len(dataset_val), len(dataset_train), len(dataset_val)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have: 15 examples, 12 are training and 3 testing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNAhKOAIjQS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CUDA_LAUNCH_BLOCKING=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pNi_tqC5IG4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "357eaa7a6a2947cfa949fe1705f9691e",
            "1426f0d4ce3b47758c9e74b7494d8ad4",
            "df5eb2a320b941a583940c4e7c4c1de8",
            "4e1e75c2a9aa4e1b89f3e92cd519ed8e",
            "fe219194d6d848bdb587a70e2067d041",
            "5665dcd4c1114bbeb51c6e0ecb4cbff3",
            "6075e81c785e4e3cb3953b967b288230",
            "2269c10f5d2b425e97116372097c4de1"
          ]
        },
        "outputId": "4b8fc434-e812-4627-92e4-1cd91d25afb8"
      },
      "source": [
        "num_classes = 4 # 3 class (number of classname) + 1 class (background)\n",
        "# Proceed with GPU for learning but if GPU is not available, use CPU\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# Get the model using our helper function\n",
        "model = get_instance_segmentation_model(num_classes)\n",
        "# Move model to GPU or CPU\n",
        "model.to(device)\n",
        "\n",
        "# construct an optimizer\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005,\n",
        "                            momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "# Construct a learning rate scheduler\n",
        "# Learning rate scheduler decreases by 10x every 5 epochs\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                            step_size=5,\n",
        "                                            gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "357eaa7a6a2947cfa949fe1705f9691e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=167502836.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF36PGTR8KRY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c0db7631-1e70-4a28-a306-e11f9db513e0"
      },
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Train for 1 epoch and print every 10 iterations\n",
        "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
        "    # Update learning rate\n",
        "    lr_scheduler.step()\n",
        "    # Evaluate on the validation data\n",
        "    evaluate(model, data_loader_val, device=device)\n",
        "torch.save(model.state_dict(), \"model.pth\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [0]  [0/3]  eta: 0:00:07  lr: 0.002502  loss: 0.7067 (0.7067)  loss_classifier: 0.1940 (0.1940)  loss_box_reg: 0.0806 (0.0806)  loss_objectness: 0.1585 (0.1585)  loss_rpn_box_reg: 0.2736 (0.2736)  time: 2.5526  data: 0.4445  max mem: 3281\n",
            "Epoch: [0]  [2/3]  eta: 0:00:02  lr: 0.005000  loss: 0.6200 (0.5611)  loss_classifier: 0.1940 (0.1755)  loss_box_reg: 0.0806 (0.0815)  loss_objectness: 0.1320 (0.1324)  loss_rpn_box_reg: 0.1703 (0.1717)  time: 2.1466  data: 0.1544  max mem: 3281\n",
            "Epoch: [0] Total time: 0:00:06 (2.1676 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [0/3]  eta: 0:00:01  model_time: 0.2508 (0.2508)  evaluator_time: 0.0021 (0.0021)  time: 0.4285  data: 0.1737  max mem: 3281\n",
            "Test:  [2/3]  eta: 0:00:00  model_time: 0.2421 (0.2437)  evaluator_time: 0.0011 (0.0013)  time: 0.3064  data: 0.0600  max mem: 3281\n",
            "Test: Total time: 0:00:00 (0.3263 s / it)\n",
            "Averaged stats: model_time: 0.2421 (0.2437)  evaluator_time: 0.0011 (0.0013)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Epoch: [1]  [0/3]  eta: 0:00:07  lr: 0.005000  loss: 0.4080 (0.4080)  loss_classifier: 0.1339 (0.1339)  loss_box_reg: 0.0870 (0.0870)  loss_objectness: 0.1030 (0.1030)  loss_rpn_box_reg: 0.0841 (0.0841)  time: 2.4392  data: 0.4982  max mem: 3281\n",
            "Epoch: [1]  [2/3]  eta: 0:00:02  lr: 0.005000  loss: 0.6296 (0.5898)  loss_classifier: 0.1339 (0.1139)  loss_box_reg: 0.0800 (0.0601)  loss_objectness: 0.1648 (0.1606)  loss_rpn_box_reg: 0.3386 (0.2552)  time: 2.1039  data: 0.1725  max mem: 3281\n",
            "Epoch: [1] Total time: 0:00:06 (2.1254 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [0/3]  eta: 0:00:01  model_time: 0.2488 (0.2488)  evaluator_time: 0.0042 (0.0042)  time: 0.4080  data: 0.1530  max mem: 3281\n",
            "Test:  [2/3]  eta: 0:00:00  model_time: 0.2462 (0.2435)  evaluator_time: 0.0042 (0.0044)  time: 0.3039  data: 0.0546  max mem: 3281\n",
            "Test: Total time: 0:00:00 (0.3246 s / it)\n",
            "Averaged stats: model_time: 0.2462 (0.2435)  evaluator_time: 0.0042 (0.0044)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Epoch: [2]  [0/3]  eta: 0:00:07  lr: 0.005000  loss: 0.3138 (0.3138)  loss_classifier: 0.1191 (0.1191)  loss_box_reg: 0.0673 (0.0673)  loss_objectness: 0.1016 (0.1016)  loss_rpn_box_reg: 0.0258 (0.0258)  time: 2.3922  data: 0.4561  max mem: 3281\n",
            "Epoch: [2]  [2/3]  eta: 0:00:02  lr: 0.005000  loss: 0.5527 (0.5957)  loss_classifier: 0.1475 (0.1567)  loss_box_reg: 0.0673 (0.0764)  loss_objectness: 0.2358 (0.1965)  loss_rpn_box_reg: 0.1126 (0.1662)  time: 2.0935  data: 0.1581  max mem: 3281\n",
            "Epoch: [2] Total time: 0:00:06 (2.1144 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [0/3]  eta: 0:00:01  model_time: 0.2548 (0.2548)  evaluator_time: 0.0051 (0.0051)  time: 0.4440  data: 0.1818  max mem: 3281\n",
            "Test:  [2/3]  eta: 0:00:00  model_time: 0.2416 (0.2460)  evaluator_time: 0.0043 (0.0043)  time: 0.3146  data: 0.0625  max mem: 3281\n",
            "Test: Total time: 0:00:01 (0.3359 s / it)\n",
            "Averaged stats: model_time: 0.2416 (0.2460)  evaluator_time: 0.0043 (0.0043)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Epoch: [3]  [0/3]  eta: 0:00:07  lr: 0.005000  loss: 0.5143 (0.5143)  loss_classifier: 0.1490 (0.1490)  loss_box_reg: 0.0666 (0.0666)  loss_objectness: 0.2085 (0.2085)  loss_rpn_box_reg: 0.0901 (0.0901)  time: 2.4893  data: 0.5321  max mem: 3281\n",
            "Epoch: [3]  [2/3]  eta: 0:00:02  lr: 0.005000  loss: 0.5143 (0.5571)  loss_classifier: 0.1490 (0.1598)  loss_box_reg: 0.0820 (0.0984)  loss_objectness: 0.1658 (0.1418)  loss_rpn_box_reg: 0.1541 (0.1571)  time: 2.1312  data: 0.1841  max mem: 3281\n",
            "Epoch: [3] Total time: 0:00:06 (2.1521 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [0/3]  eta: 0:00:01  model_time: 0.2485 (0.2485)  evaluator_time: 0.0026 (0.0026)  time: 0.4423  data: 0.1897  max mem: 3281\n",
            "Test:  [2/3]  eta: 0:00:00  model_time: 0.2450 (0.2436)  evaluator_time: 0.0019 (0.0020)  time: 0.3120  data: 0.0651  max mem: 3281\n",
            "Test: Total time: 0:00:00 (0.3321 s / it)\n",
            "Averaged stats: model_time: 0.2450 (0.2436)  evaluator_time: 0.0019 (0.0020)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Epoch: [4]  [0/3]  eta: 0:00:06  lr: 0.005000  loss: 0.4029 (0.4029)  loss_classifier: 0.0782 (0.0782)  loss_box_reg: 0.0279 (0.0279)  loss_objectness: 0.0760 (0.0760)  loss_rpn_box_reg: 0.2209 (0.2209)  time: 2.3282  data: 0.3852  max mem: 3281\n",
            "Epoch: [4]  [2/3]  eta: 0:00:02  lr: 0.005000  loss: 0.4521 (0.4654)  loss_classifier: 0.1279 (0.1294)  loss_box_reg: 0.0643 (0.0790)  loss_objectness: 0.1114 (0.1121)  loss_rpn_box_reg: 0.1485 (0.1450)  time: 2.0882  data: 0.1406  max mem: 3281\n",
            "Epoch: [4] Total time: 0:00:06 (2.1092 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [0/3]  eta: 0:00:01  model_time: 0.2524 (0.2524)  evaluator_time: 0.0017 (0.0017)  time: 0.4403  data: 0.1845  max mem: 3281\n",
            "Test:  [2/3]  eta: 0:00:00  model_time: 0.2394 (0.2428)  evaluator_time: 0.0017 (0.0014)  time: 0.3101  data: 0.0647  max mem: 3281\n",
            "Test: Total time: 0:00:00 (0.3304 s / it)\n",
            "Averaged stats: model_time: 0.2394 (0.2428)  evaluator_time: 0.0017 (0.0014)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Epoch: [5]  [0/3]  eta: 0:00:07  lr: 0.000500  loss: 0.8007 (0.8007)  loss_classifier: 0.1231 (0.1231)  loss_box_reg: 0.0835 (0.0835)  loss_objectness: 0.1008 (0.1008)  loss_rpn_box_reg: 0.4933 (0.4933)  time: 2.4918  data: 0.5662  max mem: 3281\n",
            "Epoch: [5]  [2/3]  eta: 0:00:02  lr: 0.000500  loss: 0.4779 (0.5739)  loss_classifier: 0.1253 (0.1350)  loss_box_reg: 0.0851 (0.0953)  loss_objectness: 0.1008 (0.1035)  loss_rpn_box_reg: 0.1382 (0.2402)  time: 2.1352  data: 0.1950  max mem: 3281\n",
            "Epoch: [5] Total time: 0:00:06 (2.1585 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [0/3]  eta: 0:00:01  model_time: 0.2543 (0.2543)  evaluator_time: 0.0016 (0.0016)  time: 0.4449  data: 0.1874  max mem: 3281\n",
            "Test:  [2/3]  eta: 0:00:00  model_time: 0.2430 (0.2467)  evaluator_time: 0.0012 (0.0012)  time: 0.3120  data: 0.0628  max mem: 3281\n",
            "Test: Total time: 0:00:01 (0.3346 s / it)\n",
            "Averaged stats: model_time: 0.2430 (0.2467)  evaluator_time: 0.0012 (0.0012)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Epoch: [6]  [0/3]  eta: 0:00:06  lr: 0.000500  loss: 0.4973 (0.4973)  loss_classifier: 0.1214 (0.1214)  loss_box_reg: 0.0942 (0.0942)  loss_objectness: 0.0920 (0.0920)  loss_rpn_box_reg: 0.1897 (0.1897)  time: 2.3078  data: 0.3659  max mem: 3281\n",
            "Epoch: [6]  [2/3]  eta: 0:00:02  lr: 0.000500  loss: 0.4973 (0.5199)  loss_classifier: 0.1265 (0.1406)  loss_box_reg: 0.0942 (0.1015)  loss_objectness: 0.0920 (0.0918)  loss_rpn_box_reg: 0.1897 (0.1861)  time: 2.0717  data: 0.1328  max mem: 3281\n",
            "Epoch: [6] Total time: 0:00:06 (2.0933 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [0/3]  eta: 0:00:01  model_time: 0.2517 (0.2517)  evaluator_time: 0.0019 (0.0019)  time: 0.4278  data: 0.1724  max mem: 3281\n",
            "Test:  [2/3]  eta: 0:00:00  model_time: 0.2463 (0.2456)  evaluator_time: 0.0011 (0.0014)  time: 0.3077  data: 0.0594  max mem: 3281\n",
            "Test: Total time: 0:00:00 (0.3275 s / it)\n",
            "Averaged stats: model_time: 0.2463 (0.2456)  evaluator_time: 0.0011 (0.0014)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Epoch: [7]  [0/3]  eta: 0:00:07  lr: 0.000500  loss: 0.5479 (0.5479)  loss_classifier: 0.2058 (0.2058)  loss_box_reg: 0.1643 (0.1643)  loss_objectness: 0.1051 (0.1051)  loss_rpn_box_reg: 0.0727 (0.0727)  time: 2.4640  data: 0.5055  max mem: 3281\n",
            "Epoch: [7]  [2/3]  eta: 0:00:02  lr: 0.000500  loss: 0.5135 (0.4871)  loss_classifier: 0.1535 (0.1532)  loss_box_reg: 0.1088 (0.1155)  loss_objectness: 0.0988 (0.0871)  loss_rpn_box_reg: 0.1525 (0.1313)  time: 2.1252  data: 0.1745  max mem: 3281\n",
            "Epoch: [7] Total time: 0:00:06 (2.1456 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [0/3]  eta: 0:00:01  model_time: 0.2536 (0.2536)  evaluator_time: 0.0024 (0.0024)  time: 0.4340  data: 0.1766  max mem: 3281\n",
            "Test:  [2/3]  eta: 0:00:00  model_time: 0.2511 (0.2481)  evaluator_time: 0.0017 (0.0018)  time: 0.3117  data: 0.0607  max mem: 3281\n",
            "Test: Total time: 0:00:00 (0.3317 s / it)\n",
            "Averaged stats: model_time: 0.2511 (0.2481)  evaluator_time: 0.0017 (0.0018)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Epoch: [8]  [0/3]  eta: 0:00:07  lr: 0.000500  loss: 0.7046 (0.7046)  loss_classifier: 0.2397 (0.2397)  loss_box_reg: 0.2148 (0.2148)  loss_objectness: 0.1228 (0.1228)  loss_rpn_box_reg: 0.1272 (0.1272)  time: 2.3923  data: 0.4207  max mem: 3281\n",
            "Epoch: [8]  [2/3]  eta: 0:00:02  lr: 0.000500  loss: 0.5366 (0.4990)  loss_classifier: 0.1846 (0.1660)  loss_box_reg: 0.1488 (0.1354)  loss_objectness: 0.0822 (0.0812)  loss_rpn_box_reg: 0.1210 (0.1163)  time: 2.1089  data: 0.1514  max mem: 3281\n",
            "Epoch: [8] Total time: 0:00:06 (2.1307 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [0/3]  eta: 0:00:01  model_time: 0.2464 (0.2464)  evaluator_time: 0.0020 (0.0020)  time: 0.4052  data: 0.1547  max mem: 3281\n",
            "Test:  [2/3]  eta: 0:00:00  model_time: 0.2464 (0.2440)  evaluator_time: 0.0020 (0.0018)  time: 0.3019  data: 0.0546  max mem: 3281\n",
            "Test: Total time: 0:00:00 (0.3225 s / it)\n",
            "Averaged stats: model_time: 0.2464 (0.2440)  evaluator_time: 0.0020 (0.0018)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Epoch: [9]  [0/3]  eta: 0:00:07  lr: 0.000500  loss: 0.4081 (0.4081)  loss_classifier: 0.1593 (0.1593)  loss_box_reg: 0.1328 (0.1328)  loss_objectness: 0.0639 (0.0639)  loss_rpn_box_reg: 0.0521 (0.0521)  time: 2.5412  data: 0.5786  max mem: 3281\n",
            "Epoch: [9]  [2/3]  eta: 0:00:02  lr: 0.000500  loss: 0.4081 (0.4980)  loss_classifier: 0.1593 (0.1759)  loss_box_reg: 0.1328 (0.1450)  loss_objectness: 0.0639 (0.0706)  loss_rpn_box_reg: 0.0767 (0.1065)  time: 2.1591  data: 0.1940  max mem: 3281\n",
            "Epoch: [9] Total time: 0:00:06 (2.1805 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [0/3]  eta: 0:00:01  model_time: 0.2569 (0.2569)  evaluator_time: 0.0035 (0.0035)  time: 0.4475  data: 0.1852  max mem: 3281\n",
            "Test:  [2/3]  eta: 0:00:00  model_time: 0.2500 (0.2506)  evaluator_time: 0.0029 (0.0026)  time: 0.3204  data: 0.0659  max mem: 3281\n",
            "Test: Total time: 0:00:01 (0.3406 s / it)\n",
            "Averaged stats: model_time: 0.2500 (0.2506)  evaluator_time: 0.0029 (0.0026)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eml5aNIDqBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import ImageDraw\n",
        "\n",
        "def drawPrediction(img, label_boxes, prediction) :\n",
        "    image = Image.fromarray(img.mul(255).permute(1, 2, 0).byte().numpy())\n",
        "    draw = ImageDraw.Draw(image)\n",
        "\n",
        "    # 예측 결과를 화면에 출력\n",
        "    for elem in range(len(label_boxes)):\n",
        "        draw.rectangle([(label_boxes[elem][0], label_boxes[elem][1]),\n",
        "        (label_boxes[elem][2], label_boxes[elem][3])], \n",
        "        outline =\"green\", width =3)\n",
        "    for element in range(len(prediction[0][\"boxes\"])):\n",
        "        boxes = prediction[0][\"boxes\"][element].cpu().numpy()\n",
        "        score = np.round(prediction[0][\"scores\"][element].cpu().numpy(),\n",
        "                            decimals= 4)\n",
        "        draw.rectangle([(boxes[0], boxes[1]), (boxes[2], boxes[3])], \n",
        "        outline =\"red\", width =3)\n",
        "        draw.text((boxes[0], boxes[1]), text = str(score))\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8T-Syv18Rxq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "9ac4d98f-5ceb-43cd-d913-07f351d6324f"
      },
      "source": [
        "dataset_test = OpenDataset(test_root,'/content/drive/My Drive/test/test.csv', transforms = get_transform(train=False))\n",
        "for i in range(len(dataset_test)) :\n",
        "    img, _ = dataset_test[i]\n",
        "    label_boxes = np.array(dataset_test[i][1][\"boxes\"])\n",
        "    # put the model in evaluation mode\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        prediction = model([img.to(device)])\n",
        "    prediction\n",
        "    result = drawPrediction(img, label_boxes, prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([[165., 209., 189., 221.]], device='cuda:0'),\n",
            "  'labels': tensor([1], device='cuda:0'),\n",
            "  'scores': tensor([0.8736],\n",
            "  device='cuda:0')}]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}